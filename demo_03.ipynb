{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo of Ch3. Non-Linear Classifier\n",
    "----\n",
    "This is the sample code of TU-ETP-AD1062 Machine Learning Fundamentals.\n",
    "\n",
    "For more information, please refer to:\n",
    "https://sites.google.com/view/tu-ad1062-mlfundamentals/\n",
    "\n",
    "Notice: For the decision tree visualization, please install graphviz via the following command in Anaconda prompt:\n",
    "`conda install python-graphviz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "import sklearn.model_selection\n",
    "import sklearn.metrics\n",
    "import sklearn.svm\n",
    "import sklearn.neural_network\n",
    "import sklearn.tree\n",
    "import sklearn.ensemble\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from mlfund.dataset import Gaussian\n",
    "from mlfund.dataset import GaussianParam\n",
    "from mlfund.plot import Plot2D\n",
    "\n",
    "import graphviz\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo 1. Generate random dataset in 2-Dimension\n",
    "----\n",
    "The demo here generate two groups of 2-dimension data which are normally distributed as following:\n",
    "1. Generate 800 training data `X_train`, with corresponded label `y_train`\n",
    "2. Generate 800 testing data `X_test`, with corresponded label `y_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Training data and plot it\n",
    "np.random.seed(0)\n",
    "\n",
    "params_train = []\n",
    "\n",
    "param = GaussianParam()\n",
    "param.mean = [-1, 1.5]\n",
    "param.cov = [[0.5, 0], [0, 0.5]]\n",
    "param.N = 100\n",
    "params_train.append(param)\n",
    "\n",
    "param = GaussianParam()\n",
    "param.mean = [2, 4.5]\n",
    "param.cov = [[0.5, 0], [0, 0.5]]\n",
    "param.N = 100\n",
    "params_train.append(param)\n",
    "\n",
    "param = GaussianParam()\n",
    "param.mean = [5, 1.5]\n",
    "param.cov = [[0.5, 0], [0, 0.5]]\n",
    "param.N = 100\n",
    "params_train.append(param)\n",
    "\n",
    "param = GaussianParam()\n",
    "param.mean = [8, 4.5]\n",
    "param.cov = [[0.5, 0], [0, 0.5]]\n",
    "param.N = 100\n",
    "params_train.append(param)\n",
    "\n",
    "\n",
    "param = GaussianParam()\n",
    "param.mean = [-1, -3.5]\n",
    "param.cov = [[0.5, 0], [0, 0.5]]\n",
    "param.N = 100\n",
    "params_train.append(param)\n",
    "\n",
    "param = GaussianParam()\n",
    "param.mean = [2, -1]\n",
    "param.cov = [[0.5, 0], [0, 0.5]]\n",
    "param.N = 100\n",
    "params_train.append(param)\n",
    "\n",
    "param = GaussianParam()\n",
    "param.mean = [5, -3.5]\n",
    "param.cov = [[0.5, 0], [0, 0.5]]\n",
    "param.N = 100\n",
    "params_train.append(param)\n",
    "\n",
    "param = GaussianParam()\n",
    "param.mean = [8, -1]\n",
    "param.cov = [[0.5, 0], [0, 0.5]]\n",
    "param.N = 100\n",
    "params_train.append(param)\n",
    "\n",
    "\n",
    "X_train, y_train = Gaussian.generate(params_train)\n",
    "y_train[0:400] = 1\n",
    "y_train[400:800] = 2\n",
    "\n",
    "plot = Plot2D()\n",
    "plot.scatter(X_train, y_train)\n",
    "plot.show()\n",
    "\n",
    "\n",
    "# Generate testing data\n",
    "X_test, y_test = Gaussian.generate(params_train)\n",
    "y_test[0:400] = 1\n",
    "y_test[400:800] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo 2. Multi-Layer Perceptron (MLP)\n",
    "----\n",
    "The demo here trains the model by Multi-Layer Perceptron algorithm with `X_train`, then predict the testing data by `X_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfMLP = sklearn.neural_network.MLPClassifier(\n",
    "    hidden_layer_sizes=(10,10,4),\n",
    "    max_iter=1000,\n",
    "    tol=1e-10\n",
    ")\n",
    "clfMLP.fit(X_train, y_train)\n",
    "\n",
    "y_test_predict = clfMLP.predict(X_test)\n",
    "\n",
    "print(\"Training data:\")\n",
    "plot = Plot2D()\n",
    "plot.scatter(X_train, y_train)\n",
    "plot.classifierContour(X_train, y_train, clfMLP)\n",
    "plot.show()\n",
    "\n",
    "print(\"Testing data:\")\n",
    "print(\"MCE = %2.3f\" % sklearn.metrics.zero_one_loss(y_test, y_test_predict))\n",
    "plot = Plot2D()\n",
    "plot.scatter(X_test, y_test)\n",
    "plot.classifierContour(X_test, y_test, clfMLP)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo 3. c-Support Vector Machine (c-SVC)\n",
    "----\n",
    "The demo here trains the model by SVM with `X_train`, then predict the testing data by `X_test`\n",
    "Notice that:\n",
    "1. The number of support vectors is output via the attribute of `clfSVC.support_vectors_`\n",
    "2. The support vectors are drawn via the wrapped function `mlfund.scatterSV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfSVC = sklearn.svm.SVC(C=10, kernel='rbf')\n",
    "clfSVC.fit(X_train, y_train)\n",
    "\n",
    "y_test_predict = clfSVC.predict(X_test)\n",
    "\n",
    "print(\"Training data:\")\n",
    "print(\"#SV = %d\" % len(clfSVC.support_vectors_))\n",
    "plot = Plot2D()\n",
    "plot.scatter(X_train, y_train)\n",
    "plot.scatterCSVC(clfSVC)\n",
    "plot.classifierContour(X_train, y_train, clfSVC)\n",
    "plot.show()\n",
    "\n",
    "print(\"Testing data:\")\n",
    "print(\"MCE = %2.3f\" % sklearn.metrics.zero_one_loss(y_test, y_test_predict))\n",
    "plot = Plot2D()\n",
    "plot.scatter(X_test, y_test)\n",
    "plot.classifierContour(X_test, y_test, clfSVC)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo 4. Decision Tree Classifier\n",
    "----\n",
    "The demo here use the IRIS dataset to demonstrate the construction of decision tree\n",
    "\n",
    "Reference: http://scikit-learn.org/stable/modules/tree.html#classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "clfDT = sklearn.tree.DecisionTreeClassifier()\n",
    "clfDT = clfDT.fit(iris.data, iris.target)\n",
    "\n",
    "dot_data = sklearn.tree.export_graphviz(\n",
    "    clfDT,\n",
    "    out_file=None,\n",
    "    feature_names=iris.feature_names,\n",
    "    class_names=iris.target_names,\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    special_characters=True)\n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo 5. Gradient Boost Classifier\n",
    "----\n",
    "The demo here trains the model by Gradient Boost with `X_train`, then predict the testing data by `X_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfGBDT = sklearn.ensemble.GradientBoostingClassifier(max_depth=3, n_estimators=5)\n",
    "clfGBDT = clfGBDT.fit(X_train, y_train)\n",
    "\n",
    "y_test_predict = clfGBDT.predict(X_test)\n",
    "\n",
    "print(\"Training data:\")\n",
    "plot = Plot2D()\n",
    "plot.scatter(X_train, y_train)\n",
    "plot.scatterCSVC(clfGBDT)\n",
    "plot.classifierContour(X_train, y_train, clfGBDT)\n",
    "plot.show()\n",
    "\n",
    "print(\"Testing data:\")\n",
    "print(\"MCE = %2.3f\" % sklearn.metrics.zero_one_loss(y_test, y_test_predict))\n",
    "plot = Plot2D()\n",
    "plot.scatter(X_test, y_test)\n",
    "plot.classifierContour(X_test, y_test, clfGBDT)\n",
    "plot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
